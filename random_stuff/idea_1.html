<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Idea 1 - Web Scraping with GPT-4o</title>
    <link rel="stylesheet" href="../stylesheets/styles.css">
    <style>
        body {
            padding: 0;
            margin: 0;
        }
        header {
            position: fixed;
            top: 0;
            width: 100%;
            background-color: white;
            text-align: center;
            padding: 20px 0;
            z-index: 1000;
        }
        main {
            margin-top: 120px; /* Reduced to provide space for fixed header */
            padding-top: 20px;
            padding-bottom: 80px; /* Added padding to the bottom to avoid overlap with the footer */
        }
        .indented-section {
            margin-left: 20%;
            width: 60%;
        }
        h1 {
            margin: 0;
            padding: 0;
        }
        p {
            margin-top: 20px;
        }
        .custom-hr {
            border: 0;
            height: 1px;
            background: #ccc;
            width: 60%;
            margin: 20px auto; /* Center horizontally by setting margin to auto */
        }
        footer {
            position: fixed;
            bottom: 0;
            width: 100%;
            text-align: center;
            background-color: white;
            padding: 10px 0;
            z-index: 1000;
        }
        .responsive-img {
            max-width: 100%;
            height: auto;
        }
        .fixed-width-img {
            display: block;
            margin: auto;
            width: 750px;
            height: auto; /* Maintain proportional height */
            margin-top: 40px; /* Adjust the value as needed */
            margin-bottom: 40px; /* Adjust the value as needed */
        }

    </style>
</head>
<body>
    <header>
        <h1>Web Scraping with GPT-4o: An Inefficient Way To Avoid HTML</h1>
        <hr class="custom-hr"> <!-- Add horizontal line under the title -->
    </header>
    <main class="indented-section">
        <p>Every so often for a project, you need to do some web-scraping. For those of us that see this as a once-in-a-while task, we may be reminded of the pain of scraping, as an annoying convolution of BeautifulSoup, maybe Selenium, and maybe Chromedriver.</p> 
            
        <p>If memory serves, you need to understand the specific structure of various websites in order to get the exact information you care about, and once the website changes, all that is gone, and you may need to start over. And for any real website, there are often security barriers, request limitations, etc, making you want to avoid the day you next need to do a web-scraping project.</p>

        <p>For someone with a hammer, many things may look like a nail. As someone more well-versed in deep learning over the last five years rather than traditional software engineering (ChemEng by training), there seemed to be a silly possibility of using new SOTA Vision Language Models (VLMs) like GPT-4o to help us here.</p>

        <p>So gave it a try, it kind of worked. I'm sure there may be better applications where this is more useful, but in this case, scraping NYT articles, it helped me bypass login/anti-scraping security rules, so I appreciated it!</p>
        

        <h2>Stage 1: Scrape Web Images with Chromedriver</h2>
        <p>The first stage uses Chromedriver to pull up a browser, and scroll through a website in minimally-overlapping shots, to capture the entire page. These screenshots are saved in a directory. Using chromedriver in this way ensures that even dynamic content loaded via JavaScript is captured, providing a complete visual record of the webpage.</p>

        <p>A pretty big advantage here is that using Chromedriver with a google Chrome profile with the correct login permissions will allow you to browse, and scrape, websites that may otherwise have burdensome permission blocks.</p>

        <img src="concatenated_high_res.gif" alt="Concatenated High Resolution GIF" class="fixed-width-img">


        <h2>Stage 2: OCR with GPT-4o VLM</h2>
        <p>In the second stage, the saved screenshots are sent to the GPT-4o API to extract text. Upon casual inspection, GPT-4o does a pretty great job at extracting relevant text, which is saved to a .txt file. I'm guessing theres some sort of OCR tool that is plugged into GPT-4o, or I'd be quite surprised.

        <p>Here, there is the potential for doing other sorts of webscraping analysis that would certainly be beyond traditional BeautifulSoup style scraping; for example, if we want to include descriptive captions for images in the article transcription, this is something you would need a VLM for.</p>



        <h2>Stage 3: Synthesize Full Transcript</h2>
        <p>The last stage simply takes a directory of .txt file chunks, concatenates them in order into a single prompt, and asks GPT-4o to synthesize them into a single .txt article verbatim. Modern LLMs should have no problem doing this relatively simple task, but be careful to ask for an exact synthesis, and make sure you have sufficient output tokens to capture the whole articlec.</p>

        <h2>Analysis, and My Take</h2>
        <p>My hot take, costs, speed. When its useful. Code repo.</p>



    </main>
    <footer>
        <hr class="custom-hr"> <!-- Add horizontal line above the footer -->
        <p>&copy; 2024 Emmett Goodman</p>
    </footer>
</body>
</html>
